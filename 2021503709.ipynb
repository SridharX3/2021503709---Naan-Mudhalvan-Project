{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL9A8BdDA_4l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory paths\n",
        "path_train = '/content/drive/MyDrive/NM Dataset/train_v2/train'\n",
        "path_validation = '/content/drive/MyDrive/NM Dataset/validation_v2/validation'"
      ],
      "metadata": {
        "id": "LPOcVxOGBOYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV files\n",
        "train_csv_path = '/content/drive/MyDrive/NM Dataset/written_name_train_v2.csv'\n",
        "validation_csv_path = '/content/drive/MyDrive/NM Dataset/written_name_validation_v2.csv'"
      ],
      "metadata": {
        "id": "ZK859mhHBQQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_csv_path)\n",
        "validation_df = pd.read_csv(validation_csv_path)"
      ],
      "metadata": {
        "id": "pBVSerQaBTuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for training and validation\n",
        "train_df_sample = train_df.sample(n=10000, random_state=42)\n",
        "validation_df_sample = validation_df.sample(n=3000, random_state=42)"
      ],
      "metadata": {
        "id": "zYPh3xzIBzFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=(100, 100)):\n",
        "    image = cv2.imread(image_path)\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "    normalized_image = resized_image / 255.0\n",
        "    return normalized_image"
      ],
      "metadata": {
        "id": "q3-TnIRaCTSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess training images and labels\n",
        "train_images = []\n",
        "train_labels = []\n",
        "for idx, row in train_df_sample.iterrows():\n",
        "    image_path = os.path.join(path_train, row['FILENAME'])\n",
        "    processed_image = preprocess_image(image_path)\n",
        "    train_images.append(processed_image)\n",
        "    train_labels.append(row['IDENTITY'])"
      ],
      "metadata": {
        "id": "U4K08ZeJCWts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the paths to validation images and CSV file\n",
        "path_validation = '/content/drive/MyDrive/NM Dataset/validation_v2/validation'\n",
        "validation_csv_path = '/content/drive/MyDrive/NM Dataset/written_name_validation_v2.csv'\n",
        "\n",
        "# Check if the paths exist\n",
        "if not os.path.exists(path_validation):\n",
        "    raise FileNotFoundError(f\"Path '{path_validation}' does not exist.\")\n",
        "if not os.path.exists(validation_csv_path):\n",
        "    raise FileNotFoundError(f\"CSV file '{validation_csv_path}' does not exist.\")\n",
        "\n",
        "# Read the validation CSV file into a DataFrame\n",
        "validation_df = pd.read_csv(validation_csv_path)\n",
        "\n",
        "# Preprocess validation images and labels\n",
        "validation_images = []\n",
        "validation_labels = []\n",
        "\n",
        "for idx, row in validation_df.iterrows():  # Iterate through each row in the DataFrame\n",
        "    # Get the filename from the DataFrame\n",
        "    filename = row['FILENAME']\n",
        "\n",
        "    # Add leading zeros to the filename if it has 4 digits\n",
        "    if len(filename) == 9:  # Assuming filenames are in the format 'TRAIN_XXXX.jpg'\n",
        "        filename = filename[:6] + '0' + filename[6:]\n",
        "\n",
        "    # Construct the full path to the image\n",
        "    image_path = os.path.join(path_validation, filename)\n",
        "\n",
        "    # Check if the image exists\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Warning: Image '{image_path}' not found.\")\n",
        "        continue\n",
        "\n",
        "    # Assuming there's a function called preprocess_image that processes the image\n",
        "    try:\n",
        "        processed_image = preprocess_image(image_path)\n",
        "        validation_images.append(processed_image)\n",
        "        validation_labels.append(row['IDENTITY'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image '{image_path}': {e}\")\n",
        "\n",
        "# Check if any images were loaded\n",
        "if not validation_images:\n",
        "    print(\"No images were loaded. Please check your file paths and the preprocess_image function.\")\n"
      ],
      "metadata": {
        "id": "1X_Xn4QpCd5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of validation images loaded: {len(validation_images)}\")\n",
        "print(f\"Number of train images loaded: {len(train_images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR7HATAhg91K",
        "outputId": "85d07a23-786c-4612-b1a2-a41fe570f145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation images loaded: 5000\n",
            "Number of train images loaded: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "validation_images = np.array(validation_images)\n",
        "validation_labels = np.array(validation_labels)"
      ],
      "metadata": {
        "id": "b-q3kAfcEB1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split validation data into validation and test sets\n",
        "validation_images, test_images, validation_labels, test_labels = train_test_split(\n",
        "    validation_images, validation_labels, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "nntYySJaECrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation Images Shape:\", validation_images.shape)\n",
        "print(\"Validation Labels Shape:\", validation_labels.shape)\n",
        "print(\"Test Images Shape:\", test_images.shape)\n",
        "print(\"Test Labels Shape:\", test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk6WMkgiEsBI",
        "outputId": "33a1a90f-7dab-49cb-b641-61ede6428818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Images Shape: (2500, 100, 100, 3)\n",
            "Validation Labels Shape: (2500,)\n",
            "Test Images Shape: (2500, 100, 100, 3)\n",
            "Test Labels Shape: (2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Convert labels to numerical format\n",
        "train_labels = np.array([1 if label == 'POSITIVE_CLASS' else 0 for label in train_labels])\n",
        "validation_labels = np.array([1 if label == 'POSITIVE_CLASS' else 0 for label in validation_labels])\n",
        "test_labels = np.array([1 if label == 'POSITIVE_CLASS' else 0 for label in test_labels])\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(validation_images, validation_labels))\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNTSHTlvhlP8",
        "outputId": "06e533ab-7064-4c0b-cbd6-c664bed364ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 182s 576ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 181s 579ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 179s 571ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 185s 591ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 180s 577ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 167s 533ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 178s 570ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 177s 567ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 165s 528ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 178s 570ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "79/79 [==============================] - 11s 145ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/NM Model/NM model.h5'\n",
        "\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(\"Model saved successfully at:\", model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTN5r1MGostV",
        "outputId": "28906b0b-f3d1-40fc-b793-0c3f7e8f26d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at: /content/drive/MyDrive/NM Model/NM model.h5\n"
          ]
        }
      ]
    }
  ]
}